---
header-includes: |
  \usepackage{ctex}
---
[toc]

# update

# 开发说明

1. 按照https://alidocs.dingtalk.com/i/nodes/YndMj49yWjPzNNdLi0QMagjZJ3pmz5aA?utm_scene=person_space 所述的1.2和1.3的思路、数据使用细节、工程考虑。进行模型的实现。

# 文本排列设计和读写加速相关

数据库交互情况下，设置好索引可以加快取数效率，行数不会成为取数时长的主要瓶颈（达梦数据库除外，一张表超300万行可能会卡死）。但文本交互下的结构设计需权衡 “单文件大小和行数造成的读取时长”与“解析为算法运算的需求格式的运算时长”两方面。

## 读取加速

横表：将日时间尺度拉为多列
列表：一般的时间序列，多列为多个特征。

* 功率/负荷数据以横表设计，多列为日内不同时刻点，会增加object字段，以识别不同对象。功率/负荷数据时间尺度固定（5min/15min/1h），且不同的预测对象的数据时间范围不同。横表能较大程度减小单文件行数，避免多对象的统一时间标识造成null字符过多而占用空间。当涉及庞大数量的对象时，可采用拆分文件存储并读取的方式，此外关于横表为适配算法内部计算可能需要再转化为竖表、这块增加的计算开销可使用多进程缓解。参考file_reader_multiThread.py
* 气象存储采用竖表的形式，字段名为双元组，分别标志指标和地理位点，如"t2m_59090"。且按起报时间分为不同的文本文件。详见下面的测试：189M文件约为近1年的广东省86个气象位点的hres12批次预报、取涉及温度、辐射、矢量风速共4个指标的文件大小。考虑到气象站点和指标较多，加上预报气象距起报时间的时滞是变尺度的，横表设计会有较多的null字符，增加文件内存，且如果从横表读入、为适配算法内部计算再转化为竖表df、也会增加额外的时间开销。关于列表会增加文件行数（影响解析速度）的情况，可以采用多文件拆分+多线程读取+多进程pandas运算的方式缓解。

| 测试号 | 代码                                                     | 文件情况                          | num_workers             | 用时（秒） | 备注    |
| ------ | -------------------------------------------------------- | --------------------------------- | ----------------------- | ---------- | ------- |
| base   | 逐个遍历文件+转df （file_reader.py）                     | 1个文件，189M, ~40000行           | 1                       | ~8         | Default |
| 1      | 多线程遍历文件+多进程转df （file_reader_multiThread.py） |                                   | 1个文件，189M, ~40000行 | 1          | ~12     |
| 2      | 逐个遍历文件+转df （file_reader.py）                     | 100个文件，共189M, 单个文件~400行 | 1                       | ~5.5       | Default |
| 3      | 多线程遍历文件+多进程转df                                | 100个文件，共189M, 单个文件~400行 | 1                       | ~2.2       | Default |
| 4      | 多线程遍历文件+多进程转df                                | 100个文件，共189M, 单个文件~400行 | 2                       | ~1.6       | Default |
| 5      | 多线程遍历文件+多进程转df                                | 100个文件，共189M, 单个文件~400行 | 4/8                     | ~1.2       | Default |

## 写出加速

新能源机组的场景预测，尽管使用横表设计，写出文件行数=机组数*场景数，网省级别的机组数量在1000以上，全空间场景数至少1000，典型场景数可能20以内，仍涉及万~百万行的写出。df遍历行的写出速度极慢（file_outputer.py），但如果是列表的写出会显著加速（file_outputer_dict.py）。故需注意输出遍历的存储格式，建议以{block_name: [[row1], [row2], ...]}的方式。改造前后的速度对比如下。当前file_outputer_dict.py为遍历输出对象的串行写出，后续有必要还可以类似file_reader_multiThread.py的方式，改造为多线程/细分文件写出。

| 测试号 | 代码                                                                           | 文件情况                     | num_workers | 用时（min） | 备注 |
| ------ | ------------------------------------------------------------------------------ | ---------------------------- | ----------- | ----------- | ---- |
| base   | 输出对象存为df，遍历df的行转list写出 （file_outputer.py）                      | 19个文件，约1.2g, 共~250万行 | 1           | 16          |      |
| 1      | 输出对象直接存为原始数据结构，dict，元素为嵌套的list （file_outputer_dict.py） | 19个文件，约1.2g, 共~250万行 | 1           | 1           |      |

## 工程化todo

1. 设置样本自动选择方案，30d还是不太合适样本太少，不稳定
2. 设置验证集稍微早停一下
3. 设置最大迭代次数大一点，如8000
4. 设置接口规范
5. file_outputer_dict.py改为多线程写出
